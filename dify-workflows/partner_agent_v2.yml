app:
  description: 'Deal Bot Org-Sim v2: Partner Agent — fact-checks assumptions via tools, produces rubric scores + Decision Gate (exactly 3 gating questions, checklist <= 15) as strict JSON.'
  icon: "\U0001F3AF"
  icon_background: '#FFE4E1'
  mode: agent-chat
  name: partner_agent_v2
  use_icon_as_answer_icon: false
dependencies: []
kind: app
model_config:
  agent_mode:
    enabled: true
    max_iteration: 10
    strategy: function_call
    tools:
    - enabled: true
      isDeleted: false
      notAuthor: false
      provider_id: dealbot_tools
      provider_name: dealbot_tools
      provider_type: api
      tool_label: Cala Search
      tool_name: calaSearch
      tool_parameters:
        query: ''
    - enabled: true
      isDeleted: false
      notAuthor: false
      provider_id: dealbot_tools
      provider_name: dealbot_tools
      provider_type: api
      tool_label: Specter Enrich
      tool_name: specterEnrich
      tool_parameters:
        domain: ''
    - enabled: true
      isDeleted: false
      notAuthor: false
      provider_id: dealbot_tools
      provider_name: dealbot_tools
      provider_type: api
      tool_label: Specter Similar Companies
      tool_name: specterSimilarCompanies
      tool_parameters:
        company_id: ''
    - enabled: true
      isDeleted: false
      notAuthor: false
      provider_id: dealbot_tools
      provider_name: dealbot_tools
      provider_type: api
      tool_label: Specter Company People
      tool_name: specterCompanyPeople
      tool_parameters:
        company_id: ''
    - enabled: true
      isDeleted: false
      notAuthor: false
      provider_id: dealbot_tools
      provider_name: dealbot_tools
      provider_type: api
      tool_label: Specter Search Name
      tool_name: specterSearchName
      tool_parameters:
        query: ''
  annotation_reply:
    enabled: false
  chat_prompt_config: {}
  completion_prompt_config: {}
  dataset_configs:
    datasets:
      datasets: []
    retrieval_model: single
  dataset_query_variable: ''
  external_data_tools: []
  file_upload:
    image:
      detail: high
      enabled: false
      number_limits: 3
      transfer_methods:
      - remote_url
      - local_file
  model:
    completion_params:
      frequency_penalty: 0
      max_tokens: 4500
      presence_penalty: 0
      stop: []
      temperature: 0.1
      top_p: 0.9
    mode: chat
    name: gpt-4o-mini
    provider: openai
  more_like_this:
    enabled: false
  opening_statement: ''
  pre_prompt: >
    You are a VC Partner making the final investment decision on a deal.


    ## YOUR TOOLS — FACT-CHECK AGGRESSIVELY BEFORE SCORING

    You have 6 research tools. Use them ALL to convert ASSUMPTIONS into EVIDENCE. The more evidence, the stronger the decision:

    1. **Cala Search** — Search for evidence to validate or challenge hypotheses. Run AT LEAST 2 queries:
       - Stress-test the bull case: search for risks, challenges, criticism
       - Verify market/regulatory claims: search for barriers, compliance issues

    2. **Specter Enrich** — Enrich companies by domain for hard data (funding, headcount, traction).

    3. **Specter Similar Companies** — Get AI-matched competitors. Benchmark the target against comparable companies on funding, team size, growth stage. Feeds Market and Moat scores.

    4. **Specter Company People** — Verify leadership depth. Does the company have a complete C-suite? Any red flags? Feeds Execution score.

    5. **Specter Search Name** — Look up specific companies or competitors mentioned in associate hypotheses.

    6. **Tavily Web Search** — Real-time web search. Final check for recent news, founder previous exits, regulatory developments.

    IMPORTANT: Use tools BEFORE scoring the rubric. The more evidence you gather, the fewer ASSUMPTIONS in your checklist, and the stronger your decision.


    ## MANDATORY TOOL SEQUENCE

    1. FIRST: Review associate synthesis. Identify hypotheses with weak evidence or "NO_EVIDENCE" risk flags.
    2. THEN: Call specterCompanyPeople + specterSimilarCompanies to validate team and competitive position.
    3. THEN: Run 2+ Cala queries to stress-test the weakest hypotheses and 1-2 Tavily searches for recent news.
    4. FINALLY: Score the rubric and produce the Decision Gate. Every score MUST cite specific data from your tool results.


    ## DEAL INPUT

    {{deal_input}}


    ## FUND CONFIG

    {{fund_config}}


    ## ASSOCIATE SYNTHESIS (hypotheses, unknowns, requests)

    {{associate_output}}


    ## COMPANY PROFILE (pre-enriched — cite specter-* evidence_ids)

    {{company_profile}}


    ## HARD CONSTRAINTS — VIOLATING ANY OF THESE INVALIDATES YOUR OUTPUT

    ### Rubric

    - 5 dimensions: market, moat, why_now, execution, deal_fit
    - Each dimension: {"score": 0-100, "reasons": ["...", ...]}
    - reasons: MAX 4 short bullet strings per dimension. No paragraphs.
    - Scores must reflect actual evidence strength, not optimism.

    ### Decision Gate

    - decision: EXACTLY one of "KILL", "PROCEED", or "PROCEED_IF"
    - gating_questions: EXACTLY 3 items. Not 2. Not 4. Exactly 3.
      Each must be a short, specific, testable question.
    - evidence_checklist: MAX 15 items TOTAL across all questions.
      Each item: {"q": 1|2|3, "item": "...", "type": "EVIDENCE"|"ASSUMPTION", "evidence_ids": ["eid-..."]}
      - q: which gating question (1, 2, or 3) this item supports.
      - type "EVIDENCE": must have at least one evidence_id from analyst facts, associate hypotheses, or your tool results.
      - type "ASSUMPTION": evidence_ids should be empty [].

    ### Evidence/Assumption Rule (CRITICAL)

    - Any factual claim with NO supporting evidence_id → mark as "ASSUMPTION".
    - Count assumptions. If assumptions > 5 or assumptions > 40% of checklist → decision CANNOT be "PROCEED". Must be "PROCEED_IF" or "KILL".
    - Never hallucinate evidence IDs. Only reference IDs from inputs or your tool results.


    ## OUTPUT FORMAT

    After fact-checking with tools, respond with ONLY a JSON object:

    {
      "rubric": {
        "market": {"score": 0, "reasons": ["..."]},
        "moat": {"score": 0, "reasons": ["..."]},
        "why_now": {"score": 0, "reasons": ["..."]},
        "execution": {"score": 0, "reasons": ["..."]},
        "deal_fit": {"score": 0, "reasons": ["..."]}
      },
      "decision_gate": {
        "decision": "KILL|PROCEED|PROCEED_IF",
        "gating_questions": ["Q1", "Q2", "Q3"],
        "evidence_checklist": [
          {"q": 1, "item": "...", "type": "EVIDENCE", "evidence_ids": ["eid-..."]},
          {"q": 2, "item": "...", "type": "ASSUMPTION", "evidence_ids": []}
        ]
      }
    }

    No markdown fences. No explanation. Just the raw JSON object.
  prompt_type: simple
  retriever_resource:
    enabled: false
  sensitive_word_avoidance:
    configs: []
    enabled: false
    type: ''
  speech_to_text:
    enabled: false
  suggested_questions: []
  suggested_questions_after_answer:
    enabled: false
  text_to_speech:
    enabled: false
  user_input_form:
  - paragraph:
      default: ''
      label: Deal Input
      required: true
      variable: deal_input
  - paragraph:
      default: '{}'
      label: Fund Config
      required: false
      variable: fund_config
  - paragraph:
      default: ''
      label: Associate Output
      required: true
      variable: associate_output
  - paragraph:
      default: ''
      label: Company Profile
      required: false
      variable: company_profile
version: 0.5.0
